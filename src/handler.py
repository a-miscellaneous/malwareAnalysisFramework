import os
import shutil
from src import cfg
from src import data_proccessing as dp
from src import optuna_e as optuna
from utils import json_parser, csvCutter
from utils import best_finder
from utils import relable
from utils import featurePermutations
import json
from tqdm import tqdm





class Handler:
    def __init__(self, working_dir):
        """Handles the pathing to data processing, optimization and analysis.

        Args:
            working_dir (str): the working directory of the program
        """
        self.working_dir = working_dir
        self.tmp_dir = os.path.join(working_dir, "temp")
        self.testing_zip = os.path.join(working_dir, "testing.zip")
        self.training_zip = os.path.join(working_dir, "training.zip")
        self.testing_json = os.path.join(working_dir, cfg.testing_embeddings)
        self.training_json = os.path.join(working_dir, cfg.training_embeddings)
        self.result_csv = os.path.join(working_dir, cfg.results_folder)
        self.setup()
        
    def setup(self):
        """creates the necessary folders and files for the program to run
        """
        if os.path.exists(self.tmp_dir):
            shutil.rmtree(self.tmp_dir)
            
        self.makeExistent(self.testing_json)
        self.makeExistent(self.training_json)
        self.makeExistent(self.result_csv)
            
    
    def makeExistent(self, path):
        """creates a folder if it does not exist

        Args:
            path (str): the path to the folder
        """
        if not os.path.exists(path):
            os.mkdir(path)
        
    def createJSON(self, training, encoding):
        """creates a JSON file from a ZIP file

        Args:
            training (bool): whether the ZIP file is a training or testing set
            encoding (function): the encoding function to use

        Returns:
            str: the path to the created JSON file
        """
        folder = self.training_zip if training else self.testing_zip
        d = dp.DataProcessing(folder, encoding)
        return d.createdPath

    def optimize(self, encodedJSON, opt_func, normalize):
        """optimizes a training set using optuna

        Args:
            encodedJSON (str): the name of the JSON file
            opt_func (str): the name of the optimization function to use see src/optimizer.py
            normalize (bool): whether to normalize the data or not
        """
        name = os.path.join(self.training_json, encodedJSON)
        optuna.Evaluator(self.working_dir, name, opt_func, normalize)
        
    def analyzeJSON(self, encodedJSON, training):
        """analyzes a JSON file

        Args:
            encodedJSON (str): the name of the JSON file
            training (bool): whether the JSON file is a training or testing set
        """
        folder = self.training_json if training else self.testing_json
        json_parser.analyze_json(os.path.join(folder, encodedJSON))
        
    def optimizeALL(self, jsons, opt_functions, normalizations):
        """optimizes all training sets using optuna

        Args:
            opt_functions ([str]): the names of the optimization functions to use see src/optimizer.py
            normalizations ([bool]): whether to normalize the data or not
        """
        for file in jsons:
            for opt_func in opt_functions:
                try:
                    for normalize in normalizations:
                        self.optimize(file, opt_func, normalize)
                except:
                    continue
                    
    def generateSolution(self, encodedJSON: str, model: object) -> str:
        """generates a solution for a testing set

        Args:
            encodedJSON (str): the name of the JSON file
            model (object): the model to use

        Returns:
            str: the path to the generated solution
        """
        name = encodedJSON
        data = dp.DataProcessing(name)
        labels = model(data.dataPoints)
    
        path = os.path.join(self.result_csv, "output_" + model.__name__ + ".csv")
        with open(path, "w") as f:
            for name, label in zip(data.names, labels):
                f.write(f"{name};{label}\n")
        return path
                
    def trimCSV(self, path):
        """trims a CSV file

        Args:
            path (str): the path to the CSV file
        """
        pathT = path.replace(".csv", "_trimmed.csv")
        csvCutter.parse(path, pathT)
        
    def findBest(self):
        """finds the best models for each training set
        """
        dbPath = "sqlite:///" + os.path.join(self.working_dir, cfg.db_path)
        outPath = os.path.join(self.working_dir, cfg.dbAnalysis_path)
        best_finder.run(dbPath, outPath)
        
    def relabel(self, path) -> str:
        """relabels a JSON file

        Args:
            path (str): the path to the JSON file
        """
        output = path.replace(".json", "_relabel.json")
        return relable.changeLabels(path, output)
                
                
    def deleteFeature(self, input, index) -> str:
        """deletes a feature from a JSON file

        Args:
            input (str): the path to the input JSON file
            index (int): the index of the feature to delete
        """
        output = input.replace(".json", "_del_{index}.json")
        with open(input, 'r') as inp, open(output, 'w') as out:
            data = json.load(inp)
            for i in data['data']:
                del i[index]
            json.dump(data, out)
            
        return output
    
    def mutateAllFeatures(self, input) :
        """mutates all features of a JSON file

        Args:
            input (str): the path to the input JSON file
            maxLen (int): the maximum length of the feature
        """

        with open(input, 'r') as inp:
            data = json.load(inp)
            length = len(data['data'][0])
        print("creating all combinations...")
        print("length: " + str(length))
        l = [i for i in range(length)]
        print(l)
        combinations = featurePermutations.generate_combinations(l)
        combinations = sorted(combinations, key=len)
        # print("combinations: " + str(combinations[:10]))
        print("deleting features...")
        
        for i in tqdm(combinations):
            output =  "_".join(str(num) for num in i)
            output = input.replace(".json", f"_mut_{output}.json")
            print("output: " + output)
            with open(input, 'r') as inp, open(output, 'w') as out:
                data = json.load(inp)
                for j in data['data']:
                    # delete all indexes from j which are in i
                    j = list(filter(lambda x: x not in i, j))
                json.dump(data, out)
            self.optimize(output, "randomForestClassifierModel", False)
            # self.optimize(output, "decisionTreeClasifierModel", False)
            # self.optimize(output, "aglomeret", True)
            os.remove(output)
            
        return output

    def trainSpecificFeatures(self, json_path, features):
        """trains a model with specific features

        Args:
            json_path (str): the path to the JSON file
            features ([int]): the features to use
        """
        output =  "_".join(str(num) for num in features)
        output = json_path.replace(".json", f"_mut_{output}.json")
        with open(json_path, 'r') as inp, open(output, 'w') as out:
            data = json.load(inp)
            for j in data['data']:
                j = [j[i] for i in features]
            json.dump(data, out)
        self.optimize(output, "randomForestClassifierModel", False)
        return output