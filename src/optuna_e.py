import optuna
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import os
from src import data_proccessing as dp
from src import optimizer as opt
from src import cfg



class Evaluator:
    def __init__(self,workingPath: str, jsonPath: str, opt_func: str, normalize=False):
        """Evaluates a JSON file using optuna and a given blackbox function

        Args:
            workingPath (str): folder path for saving the database
            jsonPath (str): path to the JSON file with features
            opt_func (str): name of the blackbox function to use
            normalize (bool, optional): if the data schould be normalized. Defaults to False.
        """
        self.jsonPath = jsonPath
        self.data = dp.DataProcessing(jsonPath)
        self.opt_func = opt_func  # string
        self.normalize = normalize
        self.dbPath = "sqlite:///" + os.path.join(workingPath, cfg.db_path)
        self.run()

    def run(self):
        self.setup()
        self.splitData()
        print("Starting optimization...")
        self.study.optimize(self.optimize, n_trials=cfg.trialAmount)
        

    def setup(self):
        norm = '_norm' if self.normalize else ''
        embedding_name = os.path.basename(self.jsonPath).split(".")[0]
        name = "model_" + self.opt_func + "_" + \
            embedding_name + \
            "_study" + norm
        self.study = optuna.create_study(storage=self.dbPath,
                                         study_name=name,
                                         load_if_exists=True,
                                         direction="maximize")

    def splitData(self):
        amount = int(len(self.data.dataPoints)*cfg.splitRatio)

        self.trainData, self.testData, self.trainLabels, self.testLabels = train_test_split(
            self.data.dataPoints, self.data.labels, train_size=amount)

        # Normalization
        if self.normalize:
            print("Normalizing data...")
            scaler = StandardScaler().fit(self.trainData)
            self.data.trainData = scaler.transform(self.trainData)
            self.data.testData = scaler.transform(self.testData)

    def optimize(self, trial):
        return opt.optimizer_list[self.opt_func](trial, self.trainData, self.testData, self.trainLabels, self.testLabels)


if __name__ == "__main__":
    working_path = r'C:\Users\a_misc\Desktop\data\TU_BERLIN\WiSe_23_24\smartlab\clean\03'
    Evaluator(working_path, "pe.json", 'aglomeret', True)
