from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import ExtraTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.semi_supervised import LabelPropagation 
from sklearn.semi_supervised import LabelSpreading
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.svm import LinearSVC #(setting multi_class=”crammer_singer”)
from sklearn.linear_model import LogisticRegression #(setting multi_class=”multinomial”)
from sklearn.linear_model import LogisticRegressionCV #(setting multi_class=”multinomial”)
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import NearestCentroid
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.neighbors import RadiusNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import RidgeClassifier
from sklearn.linear_model import RidgeClassifierCV
from sklearn.svm import NuSVC
from sklearn.svm import SVC
from sklearn.gaussian_process import GaussianProcessClassifier #(setting multi_class = “one_vs_one” or “one_vs_rest”)
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.svm import LinearSVC #(setting multi_class=”ovr”)
from sklearn.linear_model import LogisticRegression #(setting multi_class=”ovr”)
from sklearn.linear_model import LogisticRegressionCV #(setting multi_class=”ovr”)
from sklearn.linear_model import SGDClassifier
from sklearn.linear_model import Perceptron
from sklearn.linear_model import PassiveAggressiveClassifier

def decisionTreeClasifierModel (trial, trainData, testData, trainLabels, testLabels):
    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy', 'log_loss'])
    splitter = trial.suggest_categorical('splitter', ['best', 'random'])
    min_samples_split = trial.suggest_int('min_samples_split', 2, 40)
    model = DecisionTreeClassifier(criterion=criterion, splitter=splitter, min_samples_split=min_samples_split)
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def extraTreeClassifierModel (trial, trainData, testData, trainLabels, testLabels):
    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])
    splitter = trial.suggest_categorical('splitter', ['best', 'random'])
    min_samples_split = trial.suggest_int('min_samples_split', 2, 40)
    model = ExtraTreeClassifier(criterion=criterion, splitter=splitter, min_samples_split=min_samples_split)
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def gaussianNBModel (trial, trainData, testData, trainLabels, testLabels):
    var_smoothing = trial.suggest_float('var_smoothing', 1e-9, 1e-1)
    model = GaussianNB(var_smoothing=var_smoothing)
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def labelPropagationModel (trial, trainData, testData, trainLabels, testLabels):
    gamma = trial.suggest_float('gamma', 1e-9, 1e-1)
    n_neighbors = trial.suggest_int('n_neighbors', 2, 40)
    model = LabelPropagation(gamma=gamma, n_neighbors=n_neighbors)
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def labelSpreadingModel (trial, trainData, testData, trainLabels, testLabels):
    gamma = trial.suggest_float('gamma', 1e-9, 1e-1)
    n_neighbors = trial.suggest_int('n_neighbors', 2, 40)
    model = LabelSpreading(gamma=gamma, n_neighbors=n_neighbors)
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def linearDiscriminantAnalysisModel (trial, trainData, testData, trainLabels, testLabels):
    solver = trial.suggest_categorical('solver', ['svd', 'lsqr', 'eigen'])
    shrinkage = trial.suggest_float('shrinkage', 1e-9, 1e-1)
    model = LinearDiscriminantAnalysis(solver=solver, shrinkage=shrinkage)
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def linearSVCModel (trial, trainData, testData, trainLabels, testLabels):
    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])
    loss = trial.suggest_categorical('loss', ['hinge', 'squared_hinge'])
    dual = trial.suggest_categorical('dual', [True, False])
    tol = trial.suggest_float('tol', 1e-9, 1e-1)
    C = trial.suggest_float('C', 1e-9, 1e-1)
    model = LinearSVC(penalty=penalty, loss=loss, dual=dual, tol=tol, C=C, multi_class='crammer_singer')
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def logisticRegressionModel (trial, trainData, testData, trainLabels, testLabels):
    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])
    solver = trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])
    dual = trial.suggest_categorical('dual', [True, False])
    tol = trial.suggest_float('tol', 1e-9, 1e-1)
    C = trial.suggest_float('C', 1e-9, 1e-1)
    model = LogisticRegression(penalty=penalty, solver=solver, dual=dual, tol=tol, C=C, multi_class='multinomial')
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def logisticRegressionCVModel (trial, trainData, testData, trainLabels, testLabels):
    Cs = trial.suggest_float('Cs', 1e-9, 1e-1)
    fit_intercept = trial.suggest_categorical('fit_intercept', [True, False])
    cv = trial.suggest_int('cv', 2, 40)
    dual = trial.suggest_categorical('dual', [True, False])
    tol = trial.suggest_float('tol', 1e-9, 1e-1)
    model = LogisticRegressionCV(Cs=Cs, fit_intercept=fit_intercept, cv=cv, dual=dual, tol=tol, multi_class='multinomial')
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def mLPClassifierModel (trial, trainData, testData, trainLabels, testLabels):
    hidden_layer_sizes = trial.suggest_categorical('hidden_layer_sizes', [1, 5, 10, 50, 100, 500, 1000])
    activation = trial.suggest_categorical('activation', ['identity', 'logistic', 'tanh', 'relu'])
    solver = trial.suggest_categorical('solver', ['lbfgs', 'sgd', 'adam'])
    alpha = trial.suggest_float('alpha', 1e-9, 1e-1)
    learning_rate = trial.suggest_categorical('learning_rate', ['constant', 'invscaling', 'adaptive'])
    learning_rate_init = trial.suggest_float('learning_rate_init', 1e-9, 1e-1)
    model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver=solver, alpha=alpha, learning_rate=learning_rate, learning_rate_init=learning_rate_init)
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def nearestCentroidModel (trial, trainData, testData, trainLabels, testLabels):
    metric = trial.suggest_categorical('metric', ['euclidean', 'manhattan', 'chebyshev', 'minkowski'])
    shrink_threshold = trial.suggest_float('shrink_threshold', 1e-9, 1e-1)
    model = NearestCentroid(metric=metric, shrink_threshold=shrink_threshold)
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def quadraticDiscriminantAnalysisModel (trial, trainData, testData, trainLabels, testLabels):
    reg_param = trial.suggest_float('reg_param', 1e-9, 1e-1)
    model = QuadraticDiscriminantAnalysis(reg_param=reg_param)
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def radiusNeighborsClassifierModel (trial, trainData, testData, trainLabels, testLabels):
    radius = trial.suggest_float('radius', 1e-9, 1e-1)
    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])
    algorithm = trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute'])
    leaf_size = trial.suggest_int('leaf_size', 2, 40)
    model = RadiusNeighborsClassifier(radius=radius, weights=weights, algorithm=algorithm, leaf_size=leaf_size)
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def randomForestClassifierModel (trial, trainData, testData, trainLabels, testLabels):
    n_estimators = trial.suggest_int('n_estimators', 2, 40)
    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])
    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2'])
    min_impurity_decrease = trial.suggest_float('min_impurity_decrease', 1e-9, 1e-1)
    model = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_features=max_features, min_impurity_decrease=min_impurity_decrease)
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def ridgeClassifierModel (trial, trainData, testData, trainLabels, testLabels):
    alpha = trial.suggest_float('alpha', 1e-9, 1e-1)
    solver = trial.suggest_categorical('solver', ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'])
    model = RidgeClassifier(alpha=alpha, solver=solver)
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def ridgeClassifierCVModel (trial, trainData, testData, trainLabels, testLabels):
    alphas = trial.suggest_float('alphas', 1e-9, 1e-1)
    fit_intercept = trial.suggest_categorical('fit_intercept', [True, False])
    cv = trial.suggest_int('cv', 2, 40)
    model = RidgeClassifierCV(alphas=alphas, fit_intercept=fit_intercept, cv=cv)
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def nuSVCModel (trial, trainData, testData, trainLabels, testLabels):
    nu = trial.suggest_float('nu', 1e-9, 1e-1)
    degree = trial.suggest_int('degree', 2, 40)
    shrinking = trial.suggest_categorical('shrinking', [True, False])
    probability = trial.suggest_categorical('probability', [True, False])
    class_weight = trial.suggest_categorical('class_weight', ['balanced', None])
    break_ties = trial.suggest_categorical('break_ties', [True, False])
    model = NuSVC(nu=nu, degree=degree, shrinking=shrinking, probability=probability, class_weight=class_weight, break_ties=break_ties)
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def sVCModel (trial, trainData, testData, trainLabels, testLabels):
    C = trial.suggest_float('C', 1e-9, 1e-1)
    degree = trial.suggest_int('degree', 2, 40)
    shrinking = trial.suggest_categorical('shrinking', [True, False])
    probability = trial.suggest_categorical('probability', [True, False])
    class_weight = trial.suggest_categorical('class_weight', ['balanced', None])
    break_ties = trial.suggest_categorical('break_ties', [True, False])
    model = SVC(C=C, degree=degree, shrinking=shrinking, probability=probability, class_weight=class_weight, break_ties=break_ties)
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def gaussianProcessClassifierModel (trial, trainData, testData, trainLabels, testLabels):
    kernel = trial.suggest_categorical('kernel', ['rbf', 'sigmoid', 'linear', 'poly'])
    multi_class = trial.suggest_categorical('multi_class', ['one_vs_one', 'one_vs_rest'])
    model = GaussianProcessClassifier(kernel=kernel, multi_class=multi_class)
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def gradientBoostingClassifierModel (trial, trainData, testData, trainLabels, testLabels):
    loss = trial.suggest_categorical('loss', ['deviance', 'exponential'])
    learning_rate = trial.suggest_float('learning_rate', 1e-9, 1e-1)
    criterion = trial.suggest_categorical('criterion', ['friedman_mse', 'mse', 'mae'])
    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2'])
    min_impurity_decrease = trial.suggest_float('min_impurity_decrease', 1e-9, 1e-1)
    model = GradientBoostingClassifier(loss=loss, learning_rate=learning_rate, criterion=criterion, max_features=max_features, min_impurity_decrease=min_impurity_decrease)
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def linearSVCModel (trial, trainData, testData, trainLabels, testLabels):
    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])
    loss = trial.suggest_categorical('loss', ['hinge', 'squared_hinge'])
    dual = trial.suggest_categorical('dual', [True, False])
    model = LinearSVC(penalty=penalty, loss=loss, dual=dual, multi_class='ovr')
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def logisticRegressionModel (trial, trainData, testData, trainLabels, testLabels):
    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])
    solver = trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])
    dual = trial.suggest_categorical('dual', [True, False])
    model = LogisticRegression(penalty=penalty, solver=solver, dual=dual, multi_class='ovr')
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def logisticRegressionCVModel (trial, trainData, testData, trainLabels, testLabels):
    fit_intercept = trial.suggest_categorical('fit_intercept', [True, False])
    dual = trial.suggest_categorical('dual', [True, False])
    model = LogisticRegressionCV(fit_intercept=fit_intercept,dual=dual, multi_class='ovr')
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def sGDClassifierModel (trial, trainData, testData, trainLabels, testLabels):
    loss = trial.suggest_categorical('loss', ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'])
    penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet'])
    alpha = trial.suggest_float('alpha', 1e-9, 1e-1)
    learning_rate = trial.suggest_categorical('learning_rate', ['constant', 'optimal', 'invscaling', 'adaptive'])
    model = SGDClassifier(loss=loss, penalty=penalty, alpha=alpha, learning_rate=learning_rate)
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def perceptronModel (trial, trainData, testData, trainLabels, testLabels):
    penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet'])
    alpha = trial.suggest_float('alpha', 1e-9, 1e-1)
    fit_intercept = trial.suggest_categorical('fit_intercept', [True, False])
    shuffle = trial.suggest_categorical('shuffle', [True, False])
    model = Perceptron(penalty=penalty, alpha=alpha, fit_intercept=fit_intercept, shuffle=shuffle)
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)

def passiveAggressiveClassifierModel (trial, trainData, testData, trainLabels, testLabels):
    C = trial.suggest_float('C', 1e-9, 1e-1)
    fit_intercept = trial.suggest_categorical('fit_intercept', [True, False])
    shuffle = trial.suggest_categorical('shuffle', [True, False])
    model = PassiveAggressiveClassifier(C=C, fit_intercept=fit_intercept, shuffle=shuffle)
    model.fit(trainData, trainLabels)
    return model.score(testData, testLabels)



