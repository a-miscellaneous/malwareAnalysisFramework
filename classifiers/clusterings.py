from sklearn.cluster import kmeans_plusplus
from sklearn.cluster import SpectralClustering
from sklearn.cluster import AgglomerativeClustering
from sklearn.cluster import DBSCAN
from sklearn.cluster import OPTICS
from sklearn.svm import OneClassSVM
from sklearn.cluster import AffinityPropagation
from sklearn.cluster import MeanShift
from sklearn.cluster import ward_tree
from sklearn.cluster import Birch
from sklearn.cluster import MiniBatchKMeans
from sklearn.cluster import FeatureAgglomeration




from sklearn.metrics.cluster import adjusted_rand_score


def SpectralClustering_model(trial, trainData, testData, trainLabels, testLabels):
    n_clusters = trial.suggest_int('n_clusters', 1, 40)

    
    clustering = SpectralClustering(
                        n_clusters=n_clusters,
                        )
    cluster2 = SpectralClustering(
                        n_clusters=n_clusters,
                        )
    vector = clustering.fit(trainData)
    vector_test = cluster2.fit(testData)
    trial.set_user_attr('score', adjusted_rand_score(vector_test.labels_, testLabels))
    return adjusted_rand_score(vector.labels_, trainLabels)



def DBSCAN_model(trial, trainData, testData, trainLabels, testLabels):
    eps = trial.suggest_float('eps', 0.1, 1.0)
    min_samples = trial.suggest_int('min_samples', 2, 40)
    
    clustering = DBSCAN(eps=eps, min_samples=min_samples)
    cluster2 = DBSCAN(eps=eps, min_samples=min_samples)
    
    vector = clustering.fit(trainData)
    vector_test = cluster2.fit(testData)
    trial.set_user_attr('score', adjusted_rand_score(vector_test.labels_, testLabels))
    return adjusted_rand_score(vector.labels_, trainLabels)

def OPTICS_model(trial, trainData, testData, trainLabels, testLabels):
    min_samples = trial.suggest_int('min_samples', 2, 40)
    max_eps = trial.suggest_float('max_eps', 0.1, 1.0)
    
    clustering = OPTICS(min_samples=min_samples, max_eps=max_eps)
    cluster2 = OPTICS(min_samples=min_samples, max_eps=max_eps)
    
    vector = clustering.fit(trainData)
    vector_test = cluster2.fit(testData)
    trial.set_user_attr('score', adjusted_rand_score(vector_test.labels_, testLabels))
    return adjusted_rand_score(vector.labels_, trainLabels)

def aglomeret_model(trial, trainData, testData, trainLabels, testLabels):
    n_clusters = trial.suggest_int('n_clusters', 1, 40)
    linkage= trial.suggest_categorical('linkage', ['ward', 'complete', 'average', 'single'])
    compute_full_tree = trial.suggest_categorical('compute_full_tree', ['auto', True, False])

    
    clustering = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage, compute_full_tree=compute_full_tree)
    cluster2 = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage, compute_full_tree=compute_full_tree)
    
    vector = clustering.fit(trainData)
    vector_test = cluster2.fit(testData)
    trial.set_user_attr('score', adjusted_rand_score(vector_test.labels_, testLabels))
    return adjusted_rand_score(vector.labels_, trainLabels)

def kmeans_model(trial, trainData, testData, trainLabels, testLabels):
    n_clusters = trial.suggest_int('n_clusters', 1, 10)
    init= trial.suggest_categorical('init', ['k-means++', 'random'])
    n_init= trial.suggest_int('n_init', 1, 10)
    max_iter= trial.suggest_int('max_iter', 1, 100)
    tol= trial.suggest_float('tol', 0.0, 1.0)
    algorithm= trial.suggest_categorical('algorithm', ['auto', 'full', 'elkan'])
    random_state= trial.suggest_int('random_state', 1, 1000)
    
    clustering = kmeans_plusplus(n_clusters=n_clusters, init=init, n_init=n_init, max_iter=max_iter, tol=tol, algorithm=algorithm, random_state=random_state)
    cluster2 = kmeans_plusplus(n_clusters=n_clusters, init=init, n_init=n_init, max_iter=max_iter, tol=tol, algorithm=algorithm, random_state=random_state)
    
    vector = clustering.fit(trainData)
    vector_test = cluster2.fit(testData)
    trial.set_user_attr('score', adjusted_rand_score(vector_test.labels_, testLabels))
    return adjusted_rand_score(vector.labels_, trainLabels)

def afinitty_propagation_model(trial, trainData, testData, trainLabels, testLabels):
    damping = trial.suggest_float('damping', 0.5, 1.0)
    convergence_iter = trial.suggest_int('convergence_iter', 1, 100)
    preference = trial.suggest_categorical('preference', ['median', 'mean'])
    
    clustering = AffinityPropagation(damping=damping, convergence_iter=convergence_iter, preference=preference)
    cluster2 = AffinityPropagation(damping=damping, convergence_iter=convergence_iter, preference=preference)
    
    vector = clustering.fit(trainData)
    vector_test = cluster2.fit(testData)
    
    trial.set_user_attr('score', adjusted_rand_score(vector_test.labels_, testLabels))
    return adjusted_rand_score(vector.labels_, trainLabels)

def MeanShift_model(trial, trainData, testData, trainLabels, testLabels):
    bandwidth = trial.suggest_float('bandwidth', 0.1, 1.0)
    
    clustering = MeanShift(bandwidth=bandwidth)
    cluster2 = MeanShift(bandwidth=bandwidth)
    
    vector = clustering.fit(trainData)
    vector_test = cluster2.fit(testData)
    
    trial.set_user_attr('score', adjusted_rand_score(vector_test.labels_, testLabels))
    return adjusted_rand_score(vector.labels_, trainLabels)
    
def ward_tree_model(trial, trainData, testData, trainLabels, testLabels):

    n_clusters = trial.suggest_int('n_clusters', 1, 40)

    
    clustering = ward_tree(n_clusters=n_clusters)
    cluster2 = ward_tree(n_clusters=n_clusters)
    
    vector = clustering.fit(trainData)
    vector_test = cluster2.fit(testData)
    
    trial.set_user_attr('score', adjusted_rand_score(vector_test.labels_, testLabels))
    return adjusted_rand_score(vector.labels_, trainLabels)

def Birch_model(trial, trainData, testData, trainLabels, testLabels):
    n_clusters = trial.suggest_int('n_clusters', 1, 40)
    branching_factor = trial.suggest_int('branching_factor', 2, 40)
    threshold = trial.suggest_float('threshold', 0.1, 1.0)
    
    clustering = Birch(n_clusters=n_clusters, branching_factor=branching_factor, threshold=threshold)
    cluster2 = Birch(n_clusters=n_clusters, branching_factor=branching_factor, threshold=threshold)
    
    vector = clustering.fit(trainData)
    vector_test = cluster2.fit(testData)
    
    trial.set_user_attr('score', adjusted_rand_score(vector_test.labels_, testLabels))
    return adjusted_rand_score(vector.labels_, trainLabels)

def MiniBatchKMeans_model(trial, trainData, testData, trainLabels, testLabels):
    n_clusters = trial.suggest_int('n_clusters', 1, 40)
    tol= trial.suggest_float('tol', 0.0, 1.0)
    algorithm= trial.suggest_categorical('algorithm', ['auto', 'full', 'elkan'])

    
    clustering = MiniBatchKMeans(n_clusters=n_clusters,  tol=tol, algorithm=algorithm)
    cluster2 = MiniBatchKMeans(n_clusters=n_clusters, tol=tol, algorithm=algorithm)
    
    vector = clustering.fit(trainData)
    vector_test = cluster2.fit(testData)
    
    trial.set_user_attr('score', adjusted_rand_score(vector_test.labels_, testLabels))
    return adjusted_rand_score(vector.labels_, trainLabels)

def FeatureAgglomeration_model(trial, trainData, testData, trainLabels, testLabels):
    n_clusters = trial.suggest_int('n_clusters', 1, 40)
    affinity= trial.suggest_categorical('affinity', ['euclidean', 'l1', 'l2', 'manhattan', 'cosine', 'precomputed'])
    linkage= trial.suggest_categorical('linkage', ['ward', 'complete', 'average', 'single'])
    
    clustering = FeatureAgglomeration(n_clusters=n_clusters, affinity=affinity, linkage=linkage)
    cluster2 = FeatureAgglomeration(n_clusters=n_clusters, affinity=affinity, linkage=linkage)
    
    vector = clustering.fit(trainData)
    vector_test = cluster2.fit(testData)
    
    trial.set_user_attr('score', adjusted_rand_score(vector_test.labels_, testLabels))
    return adjusted_rand_score(vector.labels_, trainLabels)